{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hyper-param tuning with Ray and Tune on a Simple CNN.\n",
    "https://docs.ray.io/en/latest/tune/examples/tune-pytorch-cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the necessary imports\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from src.engine import simpleCNN_engine\n",
    "from src.model_simpleCNN import SimpleCNN\n",
    "from src.dataset import SignalsDataset\n",
    "from src.preprocess import Prep_data_for_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_df = Prep_data_for_CNN().get_window_df_from_dir('./data/sample_sub_segmented_data_112.csv',\n",
    "                                                         prep_for_FMAPextract=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, uniq = Prep_data_for_CNN().prep_input_for_CNN(windowed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Not_driving', 'User1', 'User2'], dtype='<U11'),\n",
       " array([0, 1, 2], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq, np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train-test split\n",
    "np.random.seed(1)\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tr, y_tr, test_size=0.2, stratify=y_tr)\n",
    "\n",
    "class_weights = torch.tensor(compute_class_weight('balanced', classes=np.unique(y_train), y=y_train), dtype=torch.float32)\n",
    "class_weights = class_weights.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# normalizing X\n",
    "mean = X_train.mean(axis=(0, 2), keepdims=True)\n",
    "std = X_train.std(axis=(0, 2), keepdims=True)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_valid = (X_valid - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for each feature\n",
    "feature_indices = {'long_acc': 0, 'tranv_acc': 1, 'ang_vel': 2}\n",
    "\n",
    "train_datasets = {feature: SignalsDataset(X_train, y_train, idx) for feature, idx in feature_indices.items()}\n",
    "valid_datasets = {feature: SignalsDataset(X_valid, y_valid, idx) for feature, idx in feature_indices.items()}\n",
    "test_datasets = {feature: SignalsDataset(X_test, y_test, idx) for feature, idx in feature_indices.items()}\n",
    "\n",
    "## dataset for extracting feature maps from data\n",
    "all_dataset = {feature: SignalsDataset((X-mean)/std, y, idx) for feature, idx in feature_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "batch_size = 8 \n",
    "train_dl_long = DataLoader(train_datasets['long_acc'], batch_size, shuffle=True)\n",
    "train_dl_tranv = DataLoader(train_datasets['tranv_acc'], batch_size, shuffle=True)\n",
    "train_dl_angvel = DataLoader(train_datasets['ang_vel'], batch_size, shuffle=True)\n",
    "\n",
    "valid_dl_long = DataLoader(valid_datasets['long_acc'], batch_size, shuffle=False)\n",
    "valid_dl_tranv = DataLoader(valid_datasets['tranv_acc'], batch_size, shuffle=False)\n",
    "valid_dl_angvel = DataLoader(valid_datasets['ang_vel'], batch_size, shuffle=False)\n",
    "\n",
    "test_dl_long = DataLoader(test_datasets['long_acc'], batch_size, shuffle=False)\n",
    "test_dl_tranv = DataLoader(test_datasets['tranv_acc'], batch_size, shuffle=False)\n",
    "test_dl_angvel = DataLoader(test_datasets['ang_vel'], batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Hyperparameter search space\n",
    "config = {\n",
    "    \"optimizer\": tune.choice([\"adam\", \"sgd\"]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"scheduler\": tune.choice([\"step\", \"exp\", \"cos\"]),\n",
    "    \"step_size\": tune.choice([10, 20, 30, 40, 50]),\n",
    "    \"gamma\": tune.uniform(0.1, 0.9),\n",
    "    \"weight_decay\": tune.choice([0.0, 1e-4, 1e-3, 1e-2]),\n",
    "    \"epochs\": tune.choice([10, 20, 30]),\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a training function that integrates with Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import tempfile\n",
    "from ray import train, tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a training function that integrates with Ray Tune\n",
    "def train_simpl_model(config, train_datasets, valid_datasets):\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      model = SimpleCNN().to(device)\n",
    "\n",
    "      if config[\"optimizer\"] == \"adam\":\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "      elif config[\"optimizer\"] == \"sgd\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "      if config[\"scheduler\"] == \"step\":\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "      elif config[\"scheduler\"] == \"exp\":\n",
    "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config[\"gamma\"])\n",
    "      elif config[\"scheduler\"] == \"cos\":\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config[\"epochs\"])\n",
    "\n",
    "      # Load existing checkpoint through `get_checkpoint()` API.\n",
    "      if train.get_checkpoint():\n",
    "            loaded_checkpoint = train.get_checkpoint()\n",
    "            with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "                  model_state, optimizer_state, scheduler_state = torch.load(\n",
    "                  os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "                  )\n",
    "                  model.load_state_dict(model_state)\n",
    "                  optimizer.load_state_dict(optimizer_state)\n",
    "                  scheduler.load_state_dict(scheduler_state)\n",
    "      \n",
    "      train_loader = DataLoader(train_datasets, batch_size=int(config[\"batch_size\"]), \n",
    "                                shuffle=True, num_workers=4)\n",
    "      val_loader = DataLoader(valid_datasets, batch_size=int(config[\"batch_size\"]), \n",
    "                                shuffle=True, num_workers=4)\n",
    "      \n",
    "      criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "      engine = simpleCNN_engine(model, optimizer, scheduler, criterion, device)\n",
    "      \n",
    "      for epoch in range(config['epochs']):\n",
    "            train_loss, train_acc = engine.train(train_loader)\n",
    "            val_loss, val_acc, _ = engine.validate(val_loader)\n",
    "\n",
    "            \n",
    "            with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "                  path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "                  torch.save(\n",
    "                  (model.state_dict(), optimizer.state_dict(), scheduler.state_dict()), path\n",
    "                  )\n",
    "                  checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "                  train.report(\n",
    "                  {\"loss\": val_loss, \"accuracy\": val_acc},\n",
    "                  checkpoint=checkpoint,\n",
    "                  )\n",
    "            \n",
    "            engine.scheduler.step()\n",
    "\n",
    "      print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simpl_model(best_result, test_dataset):\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      best_trained_model = SimpleCNN().to(device)\n",
    "\n",
    "      checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "      if best_result.config[\"optimizer\"] == \"adam\":\n",
    "            optimizer = optim.Adam(best_trained_model.parameters(), lr=best_result.config[\"lr\"])\n",
    "      elif best_result.config[\"optimizer\"] == \"sgd\":\n",
    "            optimizer = optim.SGD(best_trained_model.parameters(), lr=best_result.config[\"lr\"])\n",
    "\n",
    "      if best_result.config[\"scheduler\"] == \"step\":\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=best_result.config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "      elif best_result.config[\"scheduler\"] == \"exp\":\n",
    "            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=best_result.config[\"gamma\"])\n",
    "      elif best_result.config[\"scheduler\"] == \"cos\":\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=best_result.config[\"epochs\"])\n",
    "\n",
    "      model_state, optimizer_state, scheduler_state = torch.load(checkpoint_path)\n",
    "      best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "\n",
    "      test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "      \n",
    "      criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "      engine = simpleCNN_engine(best_trained_model, optimizer, scheduler, criterion, device)\n",
    "      \n",
    "      test_acc = engine.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_trial_dirname_creator(trial):\n",
    "    '''A  function that generates shorter directory names for the trials'''\n",
    "    return f\"trial_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config, train_datasets, valid_datasets, test_dataset, num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "      def custom_trial_dirname_creator(trial):\n",
    "            '''A  function that generates shorter directory names for the trials'''\n",
    "            return f\"trial_{trial.trial_id}\"\n",
    "\n",
    "      scheduler = ASHAScheduler(\n",
    "            max_t=max_num_epochs,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2)\n",
    "      #train_simpl_model(config, train_datasets, valid_datasets)\n",
    "      tuner = tune.Tuner(\n",
    "            tune.with_resources(\n",
    "                  tune.with_parameters(train_simpl_model, \n",
    "                                       train_datasets=train_datasets,\n",
    "                                       valid_datasets=valid_datasets),\n",
    "                  resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n",
    "            ),\n",
    "            tune_config=tune.TuneConfig(\n",
    "                  metric=\"loss\",\n",
    "                  mode=\"min\",\n",
    "                  scheduler=scheduler,\n",
    "                  num_samples=num_samples,\n",
    "                  trial_dirname_creator=custom_trial_dirname_creator\n",
    "            ),\n",
    "            param_space=config\n",
    "      )\n",
    "      results = tuner.fit()\n",
    "      \n",
    "      best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "      print(\"Best trial config: {}\".format(best_result.config))\n",
    "      print(\"Best trial final validation loss: {}\".format(\n",
    "            best_result.metrics[\"loss\"]))\n",
    "      print(\"Best trial final validation accuracy: {}\".format(\n",
    "            best_result.metrics[\"accuracy\"]))\n",
    "\n",
    "      test_simpl_model(best_result, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"./custom.css\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load custom CSS file\n",
    "css = HTML('<link rel=\"stylesheet\" type=\"text/css\" href=\"./custom.css\">')  # Ensure the path is correct\n",
    "display(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-07-22 00:33:11</td></tr>\n",
       "<tr><td>Running for: </td><td>00:21:42.94        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.3/13.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 8.000: -1.0738124112288157 | Iter 4.000: -1.0812046686808268 | Iter 2.000: -2.9068712781700823 | Iter 1.000: -1.1085067325168185<br>Logical resource usage: 2.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">         lr</th><th>optimizer  </th><th>scheduler  </th><th style=\"text-align: right;\">  step_size</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_simpl_model_8f736_00000</td><td>TERMINATED</td><td>127.0.0.1:10112</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.341866</td><td style=\"text-align: right;\">0.0974404  </td><td>sgd        </td><td>step       </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        477.823 </td><td style=\"text-align: right;\">1.08482</td><td style=\"text-align: right;\">  73.913  </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00001</td><td>TERMINATED</td><td>127.0.0.1:21432</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.531053</td><td style=\"text-align: right;\">0.000241125</td><td>sgd        </td><td>cos        </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.6047</td><td style=\"text-align: right;\">1.10245</td><td style=\"text-align: right;\">  13.0435 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00002</td><td>TERMINATED</td><td>127.0.0.1:22076</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.83117 </td><td style=\"text-align: right;\">0.0325439  </td><td>adam       </td><td>exp        </td><td style=\"text-align: right;\">         30</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        376.591 </td><td style=\"text-align: right;\">1.07869</td><td style=\"text-align: right;\">  78.2609 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00003</td><td>TERMINATED</td><td>127.0.0.1:29936</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.742206</td><td style=\"text-align: right;\">0.0129884  </td><td>adam       </td><td>exp        </td><td style=\"text-align: right;\">         20</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.9842</td><td style=\"text-align: right;\">1.10018</td><td style=\"text-align: right;\">   8.69565</td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00004</td><td>TERMINATED</td><td>127.0.0.1:6060 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.235864</td><td style=\"text-align: right;\">0.0207294  </td><td>adam       </td><td>step       </td><td style=\"text-align: right;\">         40</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.7005</td><td style=\"text-align: right;\">1.56344</td><td style=\"text-align: right;\">  13.0435 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00005</td><td>TERMINATED</td><td>127.0.0.1:23040</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.653502</td><td style=\"text-align: right;\">0.0678513  </td><td>adam       </td><td>exp        </td><td style=\"text-align: right;\">         40</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         49.4842</td><td style=\"text-align: right;\">8.7399 </td><td style=\"text-align: right;\">  39.1304 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00006</td><td>TERMINATED</td><td>127.0.0.1:10056</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">0.698533</td><td style=\"text-align: right;\">1.36989e-05</td><td>sgd        </td><td>cos        </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         45.76  </td><td style=\"text-align: right;\">1.10952</td><td style=\"text-align: right;\">  23.1884 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00007</td><td>TERMINATED</td><td>127.0.0.1:22208</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.334891</td><td style=\"text-align: right;\">0.000618834</td><td>sgd        </td><td>exp        </td><td style=\"text-align: right;\">         40</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.9355</td><td style=\"text-align: right;\">1.1075 </td><td style=\"text-align: right;\">  78.2609 </td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00008</td><td>TERMINATED</td><td>127.0.0.1:31668</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.312437</td><td style=\"text-align: right;\">0.00519209 </td><td>sgd        </td><td>step       </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.9172</td><td style=\"text-align: right;\">1.22699</td><td style=\"text-align: right;\">   8.69565</td></tr>\n",
       "<tr><td>train_simpl_model_8f736_00009</td><td>TERMINATED</td><td>127.0.0.1:21100</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.526759</td><td style=\"text-align: right;\">0.000110641</td><td>adam       </td><td>step       </td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.3713</td><td style=\"text-align: right;\">1.10961</td><td style=\"text-align: right;\">  57.971  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:33:11,754\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/LEGION/ray_results/train_simpl_model_2024-07-22_00-11-28' in 0.0153s.\n",
      "2024-07-22 00:33:11,769\tINFO tune.py:1041 -- Total run time: 1302.97 seconds (1302.92 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'optimizer': 'adam', 'lr': 0.03254391115088484, 'scheduler': 'exp', 'step_size': 30, 'gamma': 0.8311696196633863, 'weight_decay': 0.01, 'epochs': 20, 'batch_size': 16}\n",
      "Best trial final validation loss: 1.0786944150924682\n",
      "Best trial final validation accuracy: 78.26086956521739\n",
      "Test Accuracy: 0.7906976744186046\n"
     ]
    }
   ],
   "source": [
    "main(config, train_datasets['long_acc'], valid_datasets['long_acc'], test_datasets['long_acc'], num_samples=10, max_num_epochs=10, gpus_per_trial=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
