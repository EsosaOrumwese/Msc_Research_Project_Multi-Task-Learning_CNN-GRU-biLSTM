{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver Identification using ResNet50 and GRU (RNN) at different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from src.engine import ResNet50_GRU_engine\n",
    "from src.model_driverID import ResNet50_GRU\n",
    "from src.dataset import FeatureMapDatasetImproved, FeatureMapDatasetNORoT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([172,  47, 117, 192])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "np.random.randint(low=0, high=200, size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('./data/feature_maps_labels/train/metadata.csv')\n",
    "y_train = y_train.iloc[:,1].values\n",
    "\n",
    "class_weights = torch.tensor(compute_class_weight('balanced', classes=np.unique(y_train), y=y_train), dtype=torch.float32)\n",
    "class_weights = class_weights.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot import plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed 172 \n",
    "This time I'm using the dataset class with the same augmentation as I used for the MTL model to allow for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/feature_maps_labels/'\n",
    "np.random.seed(172)\n",
    "\n",
    "train_datasets = FeatureMapDatasetImproved(base_dir, mode='train', rescale=False, augment=True)\n",
    "val_test_datasets = FeatureMapDatasetImproved(base_dir, mode='valid', rescale=False, augment=True)\n",
    "\n",
    "valid_datasets, test_datasets = random_split(val_test_datasets, [0.5, 0.5])\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_datasets, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(172)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "model = ResNet50_GRU(hidden_size=1024, num_layers=2, dropout=0.7, unfreeze_L3=True, unfreeze_L4=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00132603, weight_decay=0.00111036)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.304855)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ResNet50_GRU_engine(model, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train time: XXXmins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(172)\n",
    "\n",
    "seed_172_hist = engine.train_validation(train_dl, valid_dl, epochs=30, save_path='./model_checkpoint/seed_172_driver1D_ResNet50GRU_chkpt.pth')\n",
    "\n",
    "np.save('./model_checkpoint/seed_172_driver1D_ResNet50GRU_history.npy', np.array(seed_172_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(seed_172_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.test(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed 47\n",
    "This time I'm using the dataset class with the same augmentation as I used for the MTL model to allow for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/feature_maps_labels/'\n",
    "np.random.seed(47)\n",
    "\n",
    "train_datasets = FeatureMapDatasetImproved(base_dir, mode='train', rescale=False, augment=True)\n",
    "val_test_datasets = FeatureMapDatasetImproved(base_dir, mode='valid', rescale=False, augment=True)\n",
    "\n",
    "valid_datasets, test_datasets = random_split(val_test_datasets, [0.5, 0.5])\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_datasets, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "model = ResNet50_GRU(hidden_size=1024, num_layers=2, dropout=0.7, unfreeze_L3=True, unfreeze_L4=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00132603, weight_decay=0.00111036)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.304855)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ResNet50_GRU_engine(model, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train time: XXXmins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(47)\n",
    "\n",
    "seed_47_hist = engine.train_validation(train_dl, valid_dl, epochs=30, save_path='./model_checkpoint/seed_47_driver1D_ResNet50GRU_chkpt.pth')\n",
    "\n",
    "np.save('./model_checkpoint/seed_47_driver1D_ResNet50GRU_history.npy', np.array(seed_47_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(seed_47_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.test(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed 117\n",
    "This time I'm using the dataset class with the same augmentation as I used for the MTL model to allow for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/feature_maps_labels/'\n",
    "np.random.seed(117)\n",
    "\n",
    "train_datasets = FeatureMapDatasetImproved(base_dir, mode='train', rescale=False, augment=True)\n",
    "val_test_datasets = FeatureMapDatasetImproved(base_dir, mode='valid', rescale=False, augment=True)\n",
    "\n",
    "valid_datasets, test_datasets = random_split(val_test_datasets, [0.5, 0.5])\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_datasets, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(117)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "model = ResNet50_GRU(hidden_size=1024, num_layers=2, dropout=0.7, unfreeze_L3=True, unfreeze_L4=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00132603, weight_decay=0.00111036)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.304855)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ResNet50_GRU_engine(model, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train time: XXXmins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(117)\n",
    "\n",
    "seed_117_hist = engine.train_validation(train_dl, valid_dl, epochs=30, save_path='./model_checkpoint/seed_117_driver1D_ResNet50GRU_chkpt.pth')\n",
    "\n",
    "np.save('./model_checkpoint/seed_117_driver1D_ResNet50GRU_history.npy', np.array(seed_117_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(seed_117_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.test(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed 192\n",
    "This time I'm using the dataset class with the same augmentation as I used for the MTL model to allow for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './data/feature_maps_labels/'\n",
    "np.random.seed(192)\n",
    "\n",
    "train_datasets = FeatureMapDatasetImproved(base_dir, mode='train', rescale=False, augment=True)\n",
    "val_test_datasets = FeatureMapDatasetImproved(base_dir, mode='valid', rescale=False, augment=True)\n",
    "\n",
    "valid_datasets, test_datasets = random_split(val_test_datasets, [0.5, 0.5])\n",
    "\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "valid_dl = DataLoader(valid_datasets, batch_size, shuffle=True, num_workers=4)\n",
    "test_dl = DataLoader(test_datasets, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(192)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "model = ResNet50_GRU(hidden_size=1024, num_layers=2, dropout=0.7, unfreeze_L3=True, unfreeze_L4=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00132603, weight_decay=0.00111036)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.304855)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ResNet50_GRU_engine(model, optimizer, scheduler, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train time: XXXmins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(192)\n",
    "\n",
    "seed_192_hist = engine.train_validation(train_dl, valid_dl, epochs=30, save_path='./model_checkpoint/seed_192_driver1D_ResNet50GRU_chkpt.pth')\n",
    "\n",
    "np.save('./model_checkpoint/seed_192_driver1D_ResNet50GRU_history.npy', np.array(seed_192_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(seed_192_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.test(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
